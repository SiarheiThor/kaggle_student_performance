{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"iCTA6kl3n2O1"},"source":["# Student Performance from Game Play Using TensorFlow Decision Forests\n","\n","---\n","\n","This notebook will take you through the steps needed to train a baseline Gradient Boosted Trees Model using TensorFlow Decision Forests on the `Student Performance from Game Play` dataset made available for this competition, to predict if players will answer questions correctly.\n","We will load the data from a CSV file. Roughly, the code will look as follows:\n","\n","```\n","import tensorflow_decision_forests as tfdf\n","import pandas as pd\n","  \n","dataset = pd.read_csv(\"project/dataset.csv\")\n","tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(dataset, label=\"my_label\")\n","\n","model = tfdf.keras.GradientBoostedTreesModel()\n","model.fit(tf_dataset)\n","  \n","print(model.summary())\n","```\n","\n","We will also learn how to optimize reading of big datasets, do some feature engineering, data visualization and calculate better results using the F1-score\n","\n","\n","Decision Forests are a family of tree-based models including Random Forests and Gradient Boosted Trees. They are the best place to start when working with tabular data, and will often outperform (or provide a strong baseline) before you begin experimenting with neural networks."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["One of the key aspects of TensorFlow Decision Forests that makes it even more suitable for this competition, particularly given the runtime limitations, is that it has been extensively tested for training and inference on CPUs, making it possible to train it on lower-end machines."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zAXHC6-Tn2O5"},"source":["# Import the Required Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:50:23.344352Z","iopub.status.busy":"2023-06-08T14:50:23.343998Z","iopub.status.idle":"2023-06-08T14:50:36.079284Z","shell.execute_reply":"2023-06-08T14:50:36.077389Z","shell.execute_reply.started":"2023-06-08T14:50:23.344321Z"},"id":"IanlX-Eqn2O5","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-09 15:20:01.406654: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-09 15:20:01.464229: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-06-09 15:20:01.753512: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/thor_01/miniconda3/envs/ds2023/lib/:/home/thor_01/miniconda3/envs/ds2023/lib/python3.9/site-packages/nvidia/cudnn/lib\n","2023-06-09 15:20:01.753544: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/thor_01/miniconda3/envs/ds2023/lib/:/home/thor_01/miniconda3/envs/ds2023/lib/python3.9/site-packages/nvidia/cudnn/lib\n","2023-06-09 15:20:01.753548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","/home/thor_01/miniconda3/envs/ds2023/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n","WARNING:root:TensorFlow Decision Forests 1.2.0 is compatible with the following TensorFlow Versions: ['2.11.0']. However, TensorFlow 2.11.1 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n"]}],"source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","import tensorflow_decision_forests as tfdf\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import gc\n","from sklearn.metrics import f1_score, roc_auc_score"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:50:36.082463Z","iopub.status.busy":"2023-06-08T14:50:36.081650Z","iopub.status.idle":"2023-06-08T14:50:36.087972Z","shell.execute_reply":"2023-06-08T14:50:36.087204Z","shell.execute_reply.started":"2023-06-08T14:50:36.082428Z"},"id":"gLpK2yAen2O7","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow Decision Forests v1.2.0\n","TensorFlow Addons v0.20.0\n","TensorFlow v2.11.1\n"]}],"source":["print(\"TensorFlow Decision Forests v\" + tfdf.__version__)\n","print(\"TensorFlow Addons v\" + tfa.__version__)\n","print(\"TensorFlow v\" + tf.__version__)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"22DpLVFLn2O7"},"source":["# Load the Dataset\n","\n","Since the dataset is huge, some people may face memory errors while reading the dataset from the csv. To avoid this, we will try to optimize the memory used by Pandas to load and store the dataset.\n","\n","\n","When Pandas loads a dataset, by default, it automatically detects the data types of the different columns.\n","Irresepective of the maximum value that is stored in these columns, Pandas assigns `int64` for numerical columns, `float64` for float columns, `object` dtype for string columns etc.\n","\n","\n","We may be able to reduce the size of these columns in memory by downcasting numerical columns to smaller types (like `int8`, `int32`, `float32` etc.), if their maximum values don't need the larger types for storage, (like `int64`, `float64` etc.).\n","\n","\n","Similarly, Pandas automatically detects string columns as `object` datatype. To reduce memory usage of string columns which store categorical data, we specify their datatype as `category`.\n","\n","\n","Many of the columns in this dataset can be downcast to smaller types.\n","\n","We will provide a dict of `dtypes` for columns to pandas while reading the dataset."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:50:36.090265Z","iopub.status.busy":"2023-06-08T14:50:36.089168Z","iopub.status.idle":"2023-06-08T14:52:08.586271Z","shell.execute_reply":"2023-06-08T14:52:08.585333Z","shell.execute_reply.started":"2023-06-08T14:50:36.090201Z"},"id":"_XItl24kn2O7","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Full train dataset shape is (26296946, 20)\n"]}],"source":["# Reference: https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/384359\n","dtypes={\n","    'elapsed_time':np.int32,\n","    'event_name':'category',\n","    'name':'category',\n","    'level':np.uint8,\n","    'room_coor_x':np.float32,\n","    'room_coor_y':np.float32,\n","    'screen_coor_x':np.float32,\n","    'screen_coor_y':np.float32,\n","    'hover_duration':np.float32,\n","    'text':'category',\n","    'fqid':'category',\n","    'room_fqid':'category',\n","    'text_fqid':'category',\n","    'fullscreen':'category',\n","    'hq':'category',\n","    'music':'category',\n","    'level_group':'category'}\n","work_dir = 'data/predict-student-performance-from-game-play' \n","\n","train_df = pd.read_csv(work_dir+'/train.csv', dtype=dtypes)\n","print(\"Full train dataset shape is {}\".format(train_df.shape))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kwJDjr_Rn2O8"},"source":["The data is composed of 20 columns and 26296946 entries. We can see all 20 dimensions of our dataset by printing out the first 5 entries using the following code:"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:52:08.588541Z","iopub.status.busy":"2023-06-08T14:52:08.587924Z","iopub.status.idle":"2023-06-08T14:52:08.627707Z","shell.execute_reply":"2023-06-08T14:52:08.626417Z","shell.execute_reply.started":"2023-06-08T14:52:08.588502Z"},"id":"-RTRVRiWn2O8","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session_id</th>\n","      <th>index</th>\n","      <th>elapsed_time</th>\n","      <th>event_name</th>\n","      <th>name</th>\n","      <th>level</th>\n","      <th>page</th>\n","      <th>room_coor_x</th>\n","      <th>room_coor_y</th>\n","      <th>screen_coor_x</th>\n","      <th>screen_coor_y</th>\n","      <th>hover_duration</th>\n","      <th>text</th>\n","      <th>fqid</th>\n","      <th>room_fqid</th>\n","      <th>text_fqid</th>\n","      <th>fullscreen</th>\n","      <th>hq</th>\n","      <th>music</th>\n","      <th>level_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20090312431273200</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>cutscene_click</td>\n","      <td>basic</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>-413.991394</td>\n","      <td>-159.314682</td>\n","      <td>380.0</td>\n","      <td>494.0</td>\n","      <td>NaN</td>\n","      <td>undefined</td>\n","      <td>intro</td>\n","      <td>tunic.historicalsociety.closet</td>\n","      <td>tunic.historicalsociety.closet.intro</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0-4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20090312431273200</td>\n","      <td>1</td>\n","      <td>1323</td>\n","      <td>person_click</td>\n","      <td>basic</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>-413.991394</td>\n","      <td>-159.314682</td>\n","      <td>380.0</td>\n","      <td>494.0</td>\n","      <td>NaN</td>\n","      <td>Whatcha doing over there, Jo?</td>\n","      <td>gramps</td>\n","      <td>tunic.historicalsociety.closet</td>\n","      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0-4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20090312431273200</td>\n","      <td>2</td>\n","      <td>831</td>\n","      <td>person_click</td>\n","      <td>basic</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>-413.991394</td>\n","      <td>-159.314682</td>\n","      <td>380.0</td>\n","      <td>494.0</td>\n","      <td>NaN</td>\n","      <td>Just talking to Teddy.</td>\n","      <td>gramps</td>\n","      <td>tunic.historicalsociety.closet</td>\n","      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0-4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>20090312431273200</td>\n","      <td>3</td>\n","      <td>1147</td>\n","      <td>person_click</td>\n","      <td>basic</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>-413.991394</td>\n","      <td>-159.314682</td>\n","      <td>380.0</td>\n","      <td>494.0</td>\n","      <td>NaN</td>\n","      <td>I gotta run to my meeting!</td>\n","      <td>gramps</td>\n","      <td>tunic.historicalsociety.closet</td>\n","      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0-4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20090312431273200</td>\n","      <td>4</td>\n","      <td>1863</td>\n","      <td>person_click</td>\n","      <td>basic</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>-412.991394</td>\n","      <td>-159.314682</td>\n","      <td>381.0</td>\n","      <td>494.0</td>\n","      <td>NaN</td>\n","      <td>Can I come, Gramps?</td>\n","      <td>gramps</td>\n","      <td>tunic.historicalsociety.closet</td>\n","      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0-4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          session_id  index  elapsed_time      event_name   name  level  page  \\\n","0  20090312431273200      0             0  cutscene_click  basic      0   NaN   \n","1  20090312431273200      1          1323    person_click  basic      0   NaN   \n","2  20090312431273200      2           831    person_click  basic      0   NaN   \n","3  20090312431273200      3          1147    person_click  basic      0   NaN   \n","4  20090312431273200      4          1863    person_click  basic      0   NaN   \n","\n","   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n","0  -413.991394  -159.314682          380.0          494.0             NaN   \n","1  -413.991394  -159.314682          380.0          494.0             NaN   \n","2  -413.991394  -159.314682          380.0          494.0             NaN   \n","3  -413.991394  -159.314682          380.0          494.0             NaN   \n","4  -412.991394  -159.314682          381.0          494.0             NaN   \n","\n","                            text    fqid                       room_fqid  \\\n","0                      undefined   intro  tunic.historicalsociety.closet   \n","1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n","2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n","3     I gotta run to my meeting!  gramps  tunic.historicalsociety.closet   \n","4            Can I come, Gramps?  gramps  tunic.historicalsociety.closet   \n","\n","                                           text_fqid fullscreen hq music  \\\n","0               tunic.historicalsociety.closet.intro          0  0     1   \n","1  tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n","2  tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n","3  tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n","4  tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n","\n","  level_group  \n","0         0-4  \n","1         0-4  \n","2         0-4  \n","3         0-4  \n","4         0-4  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Display the first 5 examples\n","train_df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZRZu8V9NpTVN"},"source":["Please note that `session_id` uniquely identifies a user session."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ReNY-i3bn2O8"},"source":["# Load the labels\n","\n","The labels for the training dataset are stored in the `train_labels.csv`. It consists of the information on whether the user in a particular session answered each question correctly. Load the labels data by running the following code. `"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:52:08.631550Z","iopub.status.busy":"2023-06-08T14:52:08.631151Z","iopub.status.idle":"2023-06-08T14:52:08.980957Z","shell.execute_reply":"2023-06-08T14:52:08.980061Z","shell.execute_reply.started":"2023-06-08T14:52:08.631502Z"},"id":"KD4uayl2n2O9","trusted":true},"outputs":[],"source":["labels = pd.read_csv(work_dir + '/train_labels.csv')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SMKh2KAPn2O9"},"source":["Each value in the column, `session_id` is a combination of both the session and the question number. \n","We will split these into individual columns for ease of use."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:52:08.986070Z","iopub.status.busy":"2023-06-08T14:52:08.985053Z","iopub.status.idle":"2023-06-08T14:52:09.632984Z","shell.execute_reply":"2023-06-08T14:52:09.631330Z","shell.execute_reply.started":"2023-06-08T14:52:08.986015Z"},"id":"Kva8_Dbqn2O9","trusted":true},"outputs":[],"source":["labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n","labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0EQFN3vin2O9"},"source":[" Let us take a look at the first 5 entries of `labels` using the following code:"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:52:09.635535Z","iopub.status.busy":"2023-06-08T14:52:09.635072Z","iopub.status.idle":"2023-06-08T14:52:09.646935Z","shell.execute_reply":"2023-06-08T14:52:09.645519Z","shell.execute_reply.started":"2023-06-08T14:52:09.635496Z"},"id":"0eD-KZMvn2O-","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session_id</th>\n","      <th>correct</th>\n","      <th>session</th>\n","      <th>q</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20090312431273200_q1</td>\n","      <td>1</td>\n","      <td>20090312431273200</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20090312433251036_q1</td>\n","      <td>0</td>\n","      <td>20090312433251036</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20090312455206810_q1</td>\n","      <td>1</td>\n","      <td>20090312455206810</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>20090313091715820_q1</td>\n","      <td>0</td>\n","      <td>20090313091715820</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20090313571836404_q1</td>\n","      <td>1</td>\n","      <td>20090313571836404</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             session_id  correct            session  q\n","0  20090312431273200_q1        1  20090312431273200  1\n","1  20090312433251036_q1        0  20090312433251036  1\n","2  20090312455206810_q1        1  20090312455206810  1\n","3  20090313091715820_q1        0  20090313091715820  1\n","4  20090313571836404_q1        1  20090313571836404  1"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Display the first 5 examples\n","labels.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7rQSOYAYqcZ2"},"source":["Our goal is to train models for each question to predict the label `correct` for any input user session. "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"y5fK05dsn2O_"},"source":["# Prepare the dataset\n","\n","As summarized in the competition overview, the dataset presents the questions and data to us in order of `levels - level segments`(represented by column `level_group`) 0-4, 5-12, and 13-22. We have to predict the correctness of each segment's questions as they are presented. To do this we will create basic aggregate features from the relevant columns. You can create more features to boost your scores. \n","\n","First, we will create two separate lists with names of the Categorical columns and Numerical columns. We will avoid columns `fullscreen`, `hq` and `music` since they don't add any useful value for this problem statement."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:52:09.675781Z","iopub.status.busy":"2023-06-08T14:52:09.675295Z","iopub.status.idle":"2023-06-08T14:52:09.692886Z","shell.execute_reply":"2023-06-08T14:52:09.692008Z","shell.execute_reply.started":"2023-06-08T14:52:09.675734Z"},"id":"cCZWGiL_n2PA","trusted":true},"outputs":[],"source":["CATEGORICAL = [ 'event_name', 'name', 'text', 'fqid', 'room_fqid', 'text_fqid', 'text_value']\n","NUMERICAL = ['elapsed_time', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration', 'time_diff', 'room_coor_x_diff', 'room_coor_y_diff', 'screen_coor_x_diff', 'screen_coor_y_diff']"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:52:09.694645Z","iopub.status.busy":"2023-06-08T14:52:09.694108Z","iopub.status.idle":"2023-06-08T14:52:09.705948Z","shell.execute_reply":"2023-06-08T14:52:09.704842Z","shell.execute_reply.started":"2023-06-08T14:52:09.694607Z"},"trusted":true},"outputs":[],"source":["\n","\n","# count_var = ['event_name', 'fqid','room_fqid', 'text']\n","# mean_var = ['elapsed_time','level']\n","# event_var = ['navigate_click','person_click','cutscene_click','object_click','map_hover','notification_click',\n","#             'map_click','observation_click','checkpoint','elapsed_time']\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Us9sScDSn2PA"},"source":["For each categorical column, we will first group the dataset by `session_id`  and `level_group`. We will then count the number of **distinct elements** in the column for each group and store it temporarily.\n","\n","For all numerical columns, we will group the dataset by `session id` and `level_group`. Instead of counting the number of distinct elements, we will calculate the `mean` and `standard deviation` of the numerical column for each group and store it temporarily.\n","\n","After this, we will concatenate the temporary data frames we generated in the earlier step for each column to create our new feature engineered dataset."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:52:09.707628Z","iopub.status.busy":"2023-06-08T14:52:09.707151Z","iopub.status.idle":"2023-06-08T14:52:09.721286Z","shell.execute_reply":"2023-06-08T14:52:09.719704Z","shell.execute_reply.started":"2023-06-08T14:52:09.707599Z"},"trusted":true},"outputs":[],"source":["# # reference: https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\n","# def feature_engineer(train):\n","#     dfs = []\n","#     for c in count_var:\n","#         tmp = train.groupby(['session_id','level_group'])[c].agg('nunique')\n","#         tmp.name = tmp.name + '_nunique'\n","#         dfs.append(tmp)\n","#     for c in mean_var:\n","#         tmp = train.groupby(['session_id','level_group'])[c].agg('mean')\n","#         dfs.append(tmp)\n","#     for c in event_var:\n","#         tmp = train.groupby(['session_id','level_group'])[c].agg('sum')\n","#         tmp.name = tmp.name + '_sum'\n","#         dfs.append(tmp)\n","#     df = pd.concat(dfs,axis=1)\n","#     df = df.fillna(-1)\n","#     df = df.reset_index()\n","#     df = df.set_index('session_id')\n","#     return df"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:52:09.723780Z","iopub.status.busy":"2023-06-08T14:52:09.723384Z","iopub.status.idle":"2023-06-08T14:52:09.739862Z","shell.execute_reply":"2023-06-08T14:52:09.738814Z","shell.execute_reply.started":"2023-06-08T14:52:09.723739Z"},"id":"nHWhAOtTn2PA","trusted":true},"outputs":[],"source":["# Reference: https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\n","\n","# def feature_engineer(dataset_df):\n","#     dfs = []\n","#     for c in CATEGORICAL:\n","#         tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n","#         tmp.name = tmp.name + '_nunique'\n","#         dfs.append(tmp)\n","#     for c in NUMERICAL:\n","#         tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n","#         dfs.append(tmp)\n","#     for c in NUMERICAL:\n","#         tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n","#         tmp.name = tmp.name + '_std'\n","#         dfs.append(tmp)\n","#     # for c in NUMERICAL:\n","#     #     tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('sum')\n","#     #     tmp.name = tmp.name + '_std'\n","#     #     dfs.append(tmp)\n","#     dataset_df = pd.concat(dfs,axis=1)\n","#     dataset_df = dataset_df.fillna(-1)\n","#     dataset_df = dataset_df.reset_index()\n","#     dataset_df = dataset_df.set_index('session_id')\n","#     return dataset_df\n","\n","\n","def feature_engineer(df, gr):\n","\n","    #selecting the group\n","    df = df.query(f'level_group == \"{gr}\"') #\"0-4\"\n","\n","    #generating new coloumns\n","    df = df[['session_id', 'elapsed_time', 'event_name', 'name', 'level',\n","    'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y',\n","    'hover_duration', 'text', 'fqid', 'room_fqid', 'text_fqid',\n","    'level_group']]\n","    df['time_diff'] = df['elapsed_time'] - df['elapsed_time'].shift(1)\n","    df['room_coor_x_diff'] = df['room_coor_x'] - df['room_coor_x'].shift(1)\n","    df['room_coor_y_diff'] = df['room_coor_y'] - df['room_coor_y'].shift(1)\n","    df['screen_coor_x_diff'] = df['screen_coor_x'] - df['screen_coor_x'].shift(1)\n","    df['screen_coor_y_diff'] = df['screen_coor_y'] - df['screen_coor_y'].shift(1)\n","\n","    # text Not nan\n","    df['text_value'] = df['text'].isna().astype('int')\n","\n","    \n","    # Define aggregation operations for numerical and categorical columns\n","    agg_numerical = {num_col: ['mean', 'median', 'std', 'sum', 'min', 'max'] for num_col in NUMERICAL}\n","    agg_categorical = {cat_col: ['nunique','count'] for cat_col in CATEGORICAL}  # 'lambda x:x.value_counts().index[0] if x.nunique() else None' will compute mode\n","\n","    agg_dict = {**agg_numerical, **agg_categorical}\n","\n","    # Perform groupby operation for ['session_id', 'level']\n","    df_level = df.groupby(['session_id', 'level']).agg(agg_dict)\n","    df_level.columns = ['_'.join(col).strip() for col in df_level.columns.values]\n","    df_level = df_level.fillna(-1)\n","    df_level = df_level.unstack('level')\n","    df_level.columns = ['_'.join(map(str, col)) for col in df_level.columns]\n","\n","    \n","\n","    # Perform groupby operation for ['session_id', 'level_group']\n","    df_level_group = df.groupby(['session_id']).agg(agg_dict)\n","    df_level_group.columns = ['_'.join(col).strip() for col in df_level_group.columns.values]\n","    df_level_group = df_level_group.fillna(-1)\n","\n","    # Concatenate the two resulting dataframes\n","    df_final = pd.concat([df_level, df_level_group], axis=1)\n","\n","    return df_final"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:52:37.912245Z","iopub.status.busy":"2023-06-08T14:52:37.911860Z","iopub.status.idle":"2023-06-08T14:53:58.073743Z","shell.execute_reply":"2023-06-08T14:53:58.071486Z","shell.execute_reply.started":"2023-06-08T14:52:37.912209Z"},"id":"JKcoPoemn2PA","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(23562, 480)\n","(23562, 720)\n","(23562, 880)\n"]}],"source":["gc.collect()\n","#feature generation no split\n","df1_features = feature_engineer(train_df, \"0-4\" )\n","print(df1_features.shape)\n","df2_features = feature_engineer(train_df, \"5-12\" )\n","print(df2_features.shape)\n","df3_features = feature_engineer(train_df, \"13-22\")\n","print(df3_features.shape)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:54:08.303186Z","iopub.status.busy":"2023-06-08T14:54:08.302753Z","iopub.status.idle":"2023-06-08T14:54:08.631303Z","shell.execute_reply":"2023-06-08T14:54:08.630301Z","shell.execute_reply.started":"2023-06-08T14:54:08.303140Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["del train_df\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"891j7nc1n2PA"},"source":["Our feature engineered dataset is composed of 22 columns and 70686 entries. "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ij7TT3x-n2PB"},"source":["# Basic exploration of the prepared dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"s1c59fMAn2PB"},"source":["Let us print out the first 5 entries using the following code:"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.status.busy":"2023-06-08T14:52:32.778231Z","iopub.status.idle":"2023-06-08T14:52:32.780227Z","shell.execute_reply":"2023-06-08T14:52:32.780026Z","shell.execute_reply.started":"2023-06-08T14:52:32.779998Z"},"id":"mvQEsdV1n2PB","trusted":true},"outputs":[],"source":["# # Display the first 5 examples\n","# dataset_df.head(5)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.status.busy":"2023-06-08T14:52:32.783544Z","iopub.status.idle":"2023-06-08T14:52:32.785575Z","shell.execute_reply":"2023-06-08T14:52:32.785349Z","shell.execute_reply.started":"2023-06-08T14:52:32.785322Z"},"id":"DRusg-N1n2PB","trusted":true},"outputs":[],"source":["# dataset_df.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xboIq9oDn2PB"},"source":["# Numerical data distribution¶\n","\n","Let us plot some numerical columns and their value against each level_group:"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.status.busy":"2023-06-08T14:52:32.788174Z","iopub.status.idle":"2023-06-08T14:52:32.788824Z","shell.execute_reply":"2023-06-08T14:52:32.788658Z","shell.execute_reply.started":"2023-06-08T14:52:32.788634Z"},"id":"mXIiaq_bn2PC","trusted":true},"outputs":[],"source":["# figure, axis = plt.subplots(3, 2, figsize=(10, 10))\n","\n","# for name, data in dataset_df.groupby('level_group'):\n","#     axis[0, 0].plot(range(1, len(data['room_coor_x_std'])+1), data['room_coor_x_std'], label=name)\n","#     axis[0, 1].plot(range(1, len(data['room_coor_y_std'])+1), data['room_coor_y_std'], label=name)\n","#     axis[1, 0].plot(range(1, len(data['screen_coor_x_std'])+1), data['screen_coor_x_std'], label=name)\n","#     axis[1, 1].plot(range(1, len(data['screen_coor_y_std'])+1), data['screen_coor_y_std'], label=name)\n","#     axis[2, 0].plot(range(1, len(data['hover_duration'])+1), data['hover_duration_std'], label=name)\n","#     axis[2, 1].plot(range(1, len(data['elapsed_time_std'])+1), data['elapsed_time_std'], label=name)\n","    \n","\n","# axis[0, 0].set_title('room_coor_x')\n","# axis[0, 1].set_title('room_coor_y')\n","# axis[1, 0].set_title('screen_coor_x')\n","# axis[1, 1].set_title('screen_coor_y')\n","# axis[2, 0].set_title('hover_duration')\n","# axis[2, 1].set_title('elapsed_time_std')\n","\n","# for i in range(3):\n","#     axis[i, 0].legend()\n","#     axis[i, 1].legend()\n","\n","# plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"W0ex_Jkln2PC"},"source":["Now let us split the dataset into training and testing datasets:"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:54:26.451806Z","iopub.status.busy":"2023-06-08T14:54:26.451375Z","iopub.status.idle":"2023-06-08T14:54:26.457370Z","shell.execute_reply":"2023-06-08T14:54:26.456565Z","shell.execute_reply.started":"2023-06-08T14:54:26.451773Z"},"id":"OZfTcCJfn2PC","trusted":true},"outputs":[],"source":["def split_dataset(dataset, test_ratio=0.20):\n","    USER_LIST = dataset.index.unique()\n","    split = int(len(USER_LIST) * (1 - 0.20))\n","    return dataset.loc[USER_LIST[:split]], dataset.loc[USER_LIST[split:]]\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:54:28.446379Z","iopub.status.busy":"2023-06-08T14:54:28.445965Z","iopub.status.idle":"2023-06-08T14:54:28.673564Z","shell.execute_reply":"2023-06-08T14:54:28.672529Z","shell.execute_reply.started":"2023-06-08T14:54:28.446343Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["18849 examples in training, 4713 examples in testing.\n","18849 examples in training, 4713 examples in testing.\n","18849 examples in training, 4713 examples in testing.\n"]}],"source":["df1_train, df1_valid = split_dataset(df1_features)\n","print(\"{} examples in training, {} examples in testing.\".format(\n","    len(df1_train), len(df1_valid)))\n","\n","df2_train, df2_valid = split_dataset(df2_features)\n","print(\"{} examples in training, {} examples in testing.\".format(\n","    len(df2_train), len(df2_valid)))\n","\n","df3_train, df3_valid = split_dataset(df3_features)\n","print(\"{} examples in training, {} examples in testing.\".format(\n","    len(df3_train), len(df3_valid)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZnVfKZfzn2PE"},"source":["# Select a Model\n","There are several tree-based models for you to choose from.\n","\n","- RandomForestModel\n","- GradientBoostedTreesModel\n","- CartModel\n","- DistributedGradientBoostedTreesModel\n","\n","We can list all the available models in TensorFlow Decision Forests using the following code:"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:54:32.810470Z","iopub.status.busy":"2023-06-08T14:54:32.810049Z","iopub.status.idle":"2023-06-08T14:54:32.817667Z","shell.execute_reply":"2023-06-08T14:54:32.816313Z","shell.execute_reply.started":"2023-06-08T14:54:32.810424Z"},"id":"KZBdcVU1n2PE","trusted":true},"outputs":[{"data":{"text/plain":["[tensorflow_decision_forests.keras.RandomForestModel,\n"," tensorflow_decision_forests.keras.GradientBoostedTreesModel,\n"," tensorflow_decision_forests.keras.CartModel,\n"," tensorflow_decision_forests.keras.DistributedGradientBoostedTreesModel]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["tfdf.keras.get_all_models()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cPJ0fJtsWEKI"},"source":["To get started, we'll work with a Gradient Boosted Trees Model. This is one of the well-known Decision Forest training algorithms.\n","\n","A Gradient Boosted Decision Tree is a set of shallow decision trees trained sequentially. Each tree is trained to predict and then \"correct\" for the errors of the previously trained trees."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TbIeh3-En2PE"},"source":["# How can I configure a tree-based model?\n","\n","TensorFlow Decision Forests provides good defaults for you (e.g., the top ranking hyperparameters on our benchmarks, slightly modified to run in reasonable time). If you would like to configure the learning algorithm, you will find many options you can explore to get the highest possible accuracy.\n","\n","You can select a template and/or set parameters as follows:\n","```\n","rf = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")\n","```\n","\n","You can read more [here](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/GradientBoostedTreesModel)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UdibIrM-XP5-"},"source":["# Training"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BtkKMa7sXd65"},"source":["\n","We will train a model for each question to predict if the question will be answered correctly by a user. \n","There are a total of 18 questions in the dataset. Hence, we will be training 18 models, one for each question.\n","\n","We need to provide a few data structures to our training loop to store the trained models, predictions on the validation set and evaluation scores for the trained models.\n","\n","We will create these using the following code:\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:55:10.732558Z","iopub.status.busy":"2023-06-08T14:55:10.732114Z","iopub.status.idle":"2023-06-08T14:55:10.742291Z","shell.execute_reply":"2023-06-08T14:55:10.740304Z","shell.execute_reply.started":"2023-06-08T14:55:10.732524Z"},"id":"7Brds67Wn2PD","trusted":true},"outputs":[],"source":["# Fetch the unique list of user sessions in the validation dataset. We assigned \n","# `session_id` as the index of our feature engineered dataset. Hence fetching \n","# the unique values in the index column will give us a list of users in the \n","# validation set.\n","VALID_USER_LIST = df1_valid.index.unique()\n","\n","# Create a dataframe for storing the predictions of each question for all users\n","# in the validation set.\n","# For this, the required size of the data frame is: \n","# (no: of users in validation set  x no of questions).\n","# We will initialize all the predicted values in the data frame to zero.\n","# The dataframe's index column is the user `session_id`s. \n","prediction_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n","\n","# Create an empty dictionary to store the models created for each question.\n","models = {}\n","\n","# Create an empty dictionary to store the evaluation score for each question.\n","evaluation_dict ={}\n","f1_scores = {}\n","auc_scores = {}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"p1GoOMRHn2PF"},"source":["Before training the data we have to understand how `level_groups` and `questions` are associated to each other.\n","\n","In this game the first quiz checkpoint(i.e., questions 1 to 3) comes after finishing levels 0 to 4. So for training questions 1 to 3 we will use data from the `level_group` 0-4. Similarly, we will use data from the `level_group` 5-12 to train questions from 4 to 13 and data from the `level_group` 13-22 to train questions from 14 to 18.\n","\n","We will train a model for each question and store the trained model in the `models` dict."]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:55:13.339440Z","iopub.status.busy":"2023-06-08T14:55:13.338987Z","iopub.status.idle":"2023-06-08T14:55:13.585675Z","shell.execute_reply":"2023-06-08T14:55:13.584692Z","shell.execute_reply.started":"2023-06-08T14:55:13.339370Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Inference model"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["from tensorflow.keras.models import load_model"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:55:18.977955Z","iopub.status.busy":"2023-06-08T14:55:18.977522Z"},"id":"VBO3VCOJn2PF","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-09 15:21:33.408951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-09 15:21:33.409093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-09 15:21:33.409153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-09 15:21:33.409242: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-09 15:21:33.409298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-09 15:21:33.409346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 833 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n","[INFO 2023-06-09T15:21:34.589430552+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_1/assets/ with prefix 375a576baa734401\n","[INFO 2023-06-09T15:21:34.593710074+02:00 abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n","[INFO 2023-06-09T15:21:34.593762933+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 107ms/step - loss: 0.0000e+00 - accuracy: 0.7560\n","5/5 [==============================] - 1s 107ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:21:37.545693561+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_2/assets/ with prefix 8619a5faaf77467e\n","[INFO 2023-06-09T15:21:37.548275592+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 107ms/step - loss: 0.0000e+00 - accuracy: 0.9728\n","5/5 [==============================] - 1s 110ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:21:40.4288462+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_3/assets/ with prefix 3c0a956c30194d8e\n","[INFO 2023-06-09T15:21:40.432494189+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 112ms/step - loss: 0.0000e+00 - accuracy: 0.9338\n","5/5 [==============================] - 1s 104ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:21:44.03018306+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_4/assets/ with prefix f9ee2c2f779f45d5\n","[INFO 2023-06-09T15:21:44.03467537+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 170ms/step - loss: 0.0000e+00 - accuracy: 0.8080\n","5/5 [==============================] - 1s 169ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:21:48.381946238+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_5/assets/ with prefix 1c70991c7cb94820\n","[INFO 2023-06-09T15:21:48.384973414+02:00 abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n","[INFO 2023-06-09T15:21:48.385068353+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 163ms/step - loss: 0.0000e+00 - accuracy: 0.6435\n","5/5 [==============================] - 1s 168ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:21:52.855522942+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_6/assets/ with prefix a557ea475ae443ce\n","[INFO 2023-06-09T15:21:52.859886484+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 166ms/step - loss: 0.0000e+00 - accuracy: 0.7906\n","5/5 [==============================] - 1s 160ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:21:57.224275894+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_7/assets/ with prefix 5e502d6e6cec4829\n","[INFO 2023-06-09T15:21:57.228739285+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 173ms/step - loss: 0.0000e+00 - accuracy: 0.7454\n","5/5 [==============================] - 1s 161ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:01.704513635+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_8/assets/ with prefix 97015a538ce74e98\n","[INFO 2023-06-09T15:22:01.707022577+02:00 abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n","[INFO 2023-06-09T15:22:01.707106746+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 160ms/step - loss: 0.0000e+00 - accuracy: 0.6351\n","5/5 [==============================] - 1s 160ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:06.136203675+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_9/assets/ with prefix 268b0be30bd24da6\n","[INFO 2023-06-09T15:22:06.140495698+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 153ms/step - loss: 0.0000e+00 - accuracy: 0.7708\n","5/5 [==============================] - 1s 156ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:10.492903015+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_10/assets/ with prefix b1a79b6cc5ea415c\n","[INFO 2023-06-09T15:22:10.496031611+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 166ms/step - loss: 0.0000e+00 - accuracy: 0.6153\n","5/5 [==============================] - 1s 167ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:15.066659768+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_11/assets/ with prefix 8378d7a697964fca\n","[INFO 2023-06-09T15:22:15.068822514+02:00 abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n","[INFO 2023-06-09T15:22:15.068912713+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 168ms/step - loss: 0.0000e+00 - accuracy: 0.6635\n","5/5 [==============================] - 1s 159ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:19.611189793+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_12/assets/ with prefix 600804e856494cff\n","[INFO 2023-06-09T15:22:19.613376979+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 168ms/step - loss: 0.0000e+00 - accuracy: 0.8684\n","5/5 [==============================] - 1s 149ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:24.106350235+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_13/assets/ with prefix 707ab8a5083b4fe6\n","[INFO 2023-06-09T15:22:24.108806288+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 164ms/step - loss: 0.0000e+00 - accuracy: 0.7191\n","5/5 [==============================] - 1s 168ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:29.163651344+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_14/assets/ with prefix 8d2ca04ae18e482a\n","[INFO 2023-06-09T15:22:29.167864169+02:00 abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n","[INFO 2023-06-09T15:22:29.167984858+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 2s 204ms/step - loss: 0.0000e+00 - accuracy: 0.7431\n","5/5 [==============================] - 1s 190ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:34.744147975+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_15/assets/ with prefix 37b1f7b6f1894683\n","[INFO 2023-06-09T15:22:34.747846885+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 2s 190ms/step - loss: 0.0000e+00 - accuracy: 0.6488\n","5/5 [==============================] - 1s 201ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:40.330397226+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_16/assets/ with prefix 0a77a5cba05c4281\n","[INFO 2023-06-09T15:22:40.332281487+02:00 abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n","[INFO 2023-06-09T15:22:40.332388956+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 2s 205ms/step - loss: 0.0000e+00 - accuracy: 0.7481\n","5/5 [==============================] - 1s 200ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:46.112804226+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_17/assets/ with prefix f7378ed593884f1a\n","[INFO 2023-06-09T15:22:46.118512507+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 2s 191ms/step - loss: 0.0000e+00 - accuracy: 0.6991\n","5/5 [==============================] - 1s 207ms/step\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 2023-06-09T15:22:51.911827961+02:00 kernel.cc:1214] Loading model from path Tensorflow_models/model_18/assets/ with prefix eb77cb7d9ff74ef6\n","[INFO 2023-06-09T15:22:51.915387414+02:00 abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n","[INFO 2023-06-09T15:22:51.915556092+02:00 kernel.cc:1046] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 2s 200ms/step - loss: 0.0000e+00 - accuracy: 0.9497\n","5/5 [==============================] - 1s 191ms/step\n"]}],"source":["# Iterate through questions 1 to 18 to train models for each question, evaluate\n","# the trained model and store the predicted values.\n","for q_no in range(1,19):\n","    # Select level group for the question based on the q_no.\n","    if q_no<=3:\n","        train_df = df1_train\n","        valid_df = df1_valid\n","    elif q_no<=13:\n","        train_df = df2_train\n","        valid_df = df2_valid\n","    elif q_no<=22:\n","        train_df = df3_train\n","        valid_df = df3_valid\n","    \n","    \n","        \n","    # Filter the rows in the datasets based on the selected level group. \n","    \n","    train_users = train_df.index.values\n","    valid_users = valid_df.index.values\n","\n","    # Select the labels for the related q_no.\n","    train_labels = labels.loc[labels.q==q_no].set_index('session').loc[train_users]\n","    valid_labels = labels.loc[labels.q==q_no].set_index('session').loc[valid_users]\n","\n","    # Add the label to the filtered datasets.\n","    train_df[\"correct\"] = train_labels[\"correct\"]\n","    valid_df[\"correct\"] = valid_labels[\"correct\"]\n","\n","    # There's one more step required before we can train the model. \n","    # We need to convert the datatset from Pandas format (pd.DataFrame)\n","    # into TensorFlow Datasets format (tf.data.Dataset).\n","    # TensorFlow Datasets is a high performance data loading library \n","    # which is helpful when training neural networks with accelerators like GPUs and TPUs.\n","    # We are omitting `level_group`, since it is not needed for training anymore.\n","    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"correct\")\n","    valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_df, label=\"correct\")\n","\n","    # We will now create the Gradient Boosted Trees Model with default settings. \n","    # By default the model is set to train for a classification task.\n","    # gbtm = tfdf.keras.GradientBoostedTreesModel(verbose=0)\n","    # gbtm.compile(metrics=[\"accuracy\"])\n","\n","    # # Train the model.\n","    # gbtm.fit(x=train_ds)\n","\n","    gbtm = load_model(f'Tensorflow_models/model_{q_no}')\n","    \n","\n","    # Store the model\n","    models[f'{q_no}'] = gbtm\n","\n","    # Evaluate the trained model on the validation dataset and store the \n","    # evaluation accuracy in the `evaluation_dict`.\n","    # inspector = gbtm.make_inspector()\n","    # inspector.evaluation()\n","    evaluation = gbtm.evaluate(x=valid_ds,return_dict=True)\n","    evaluation_dict[q_no] = evaluation[\"accuracy\"]         \n","\n","    # Use the trained model to make predictions on the validation dataset and \n","    # store the predicted values in the `prediction_df` dataframe.\n","    predict = gbtm.predict(x=valid_ds)\n","    prediction_df.loc[valid_users, q_no-1] = predict.flatten()\n","    \n","    # Calculate the F1 score\n","    f1 = f1_score(valid_labels[\"correct\"], (predict > 0.5).astype(int))\n","    f1_scores[q_no] = f1\n","    \n","    # Calculate the AUC score\n","    auc = roc_auc_score(valid_labels[\"correct\"], predict)\n","    auc_scores[q_no] = auc\n","    \n","    \n","    del train_df, valid_df, train_labels, valid_labels\n","    gc.collect()"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T14:52:34.745979Z","iopub.status.busy":"2023-04-11T14:52:34.745474Z","iopub.status.idle":"2023-04-11T14:52:34.753017Z","shell.execute_reply":"2023-04-11T14:52:34.751991Z","shell.execute_reply.started":"2023-04-11T14:52:34.745937Z"},"id":"qPOfPkm7n2PG","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["question 1: accuracy 0.7560\n","question 2: accuracy 0.9728\n","question 3: accuracy 0.9338\n","question 4: accuracy 0.8080\n","question 5: accuracy 0.6435\n","question 6: accuracy 0.7906\n","question 7: accuracy 0.7454\n","question 8: accuracy 0.6351\n","question 9: accuracy 0.7708\n","question 10: accuracy 0.6153\n","question 11: accuracy 0.6635\n","question 12: accuracy 0.8684\n","question 13: accuracy 0.7191\n","question 14: accuracy 0.7431\n","question 15: accuracy 0.6488\n","question 16: accuracy 0.7481\n","question 17: accuracy 0.6991\n","question 18: accuracy 0.9497\n","\n","Average accuracy 0.7617346809970008\n","question 1: f1_score 0.8496\n","question 2: f1_score 0.9862\n","question 3: f1_score 0.9657\n","question 4: f1_score 0.8882\n","question 5: f1_score 0.7044\n","question 6: f1_score 0.8790\n","question 7: f1_score 0.8487\n","question 8: f1_score 0.7657\n","question 9: f1_score 0.8640\n","question 10: f1_score 0.6419\n","question 11: f1_score 0.7852\n","question 12: f1_score 0.9295\n","question 13: f1_score 0.1524\n","question 14: f1_score 0.8423\n","question 15: f1_score 0.6515\n","question 16: f1_score 0.8559\n","question 17: f1_score 0.8209\n","question 18: f1_score 0.9742\n","\n","Average f1_score 0.7617346809970008\n","question 1: auc_score 0.7470\n","question 2: auc_score 0.7445\n","question 3: auc_score 0.7398\n","question 4: auc_score 0.7525\n","question 5: auc_score 0.6932\n","question 6: auc_score 0.7159\n","question 7: auc_score 0.6759\n","question 8: auc_score 0.5919\n","question 9: auc_score 0.6867\n","question 10: auc_score 0.6610\n","question 11: auc_score 0.6361\n","question 12: auc_score 0.6422\n","question 13: auc_score 0.6713\n","question 14: auc_score 0.6856\n","question 15: auc_score 0.7082\n","question 16: auc_score 0.5692\n","question 17: auc_score 0.5848\n","question 18: auc_score 0.7161\n","\n","Average auc_score 0.7617346809970008\n"]}],"source":["for name, value in evaluation_dict.items():\n","  print(f\"question {name}: accuracy {value:.4f}\")\n","\n","print(\"\\nAverage accuracy\", sum(evaluation_dict.values())/18)\n","\n","\n","for name, value in f1_scores.items():\n","  print(f\"question {name}: f1_score {value:.4f}\")\n","\n","print(\"\\nAverage f1_score\", sum(evaluation_dict.values())/18)\n","\n","\n","for name, value in auc_scores.items():\n","  print(f\"question {name}: auc_score {value:.4f}\")\n","\n","print(\"\\nAverage auc_score\", sum(evaluation_dict.values())/18)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qtiCtfNCn2PG"},"source":["# Visualize the model\n","\n","One benefit of tree-based models is that we can easily visualize them. The default number of trees used in the Random Forests is 300. \n","\n","Let us pick one model from `models` dict and select a tree to display below."]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T14:52:43.602581Z","iopub.status.busy":"2023-04-11T14:52:43.602162Z","iopub.status.idle":"2023-04-11T14:52:43.618124Z","shell.execute_reply":"2023-04-11T14:52:43.616740Z","shell.execute_reply.started":"2023-04-11T14:52:43.602545Z"},"id":"od__6uAan2PG","trusted":true},"outputs":[{"data":{"text/html":["\n","<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n","<div id=\"tree_plot_a07530f425524bdb8aa0d84898c28d23\"></div>\n","<script>\n","/*\n"," * Copyright 2021 Google LLC.\n"," * Licensed under the Apache License, Version 2.0 (the \"License\");\n"," * you may not use this file except in compliance with the License.\n"," * You may obtain a copy of the License at\n"," *\n"," *     https://www.apache.org/licenses/LICENSE-2.0\n"," *\n"," * Unless required by applicable law or agreed to in writing, software\n"," * distributed under the License is distributed on an \"AS IS\" BASIS,\n"," * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n"," * See the License for the specific language governing permissions and\n"," * limitations under the License.\n"," */\n","\n","/**\n"," *  Plotting of decision trees generated by TF-DF.\n"," *\n"," *  A tree is a recursive structure of node objects.\n"," *  A node contains one or more of the following components:\n"," *\n"," *    - A value: Representing the output of the node. If the node is not a leaf,\n"," *      the value is only present for analysis i.e. it is not used for\n"," *      predictions.\n"," *\n"," *    - A condition : For non-leaf nodes, the condition (also known as split)\n"," *      defines a binary test to branch to the positive or negative child.\n"," *\n"," *    - An explanation: Generally a plot showing the relation between the label\n"," *      and the condition to give insights about the effect of the condition.\n"," *\n"," *    - Two children : For non-leaf nodes, the children nodes. The first\n"," *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n"," *      red). The second children is the positive one (drawn in green).\n"," *\n"," */\n","\n","/**\n"," * Plots a single decision tree into a DOM element.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!tree} raw_tree Recursive tree structure.\n"," * @param {string} canvas_id Id of the output dom element.\n"," */\n","function display_tree(options, raw_tree, canvas_id) {\n","  console.log(options);\n","\n","  // Determine the node placement.\n","  const tree_struct = d3.tree().nodeSize(\n","      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n","\n","  // Boundaries of the node placement.\n","  let x_min = Infinity;\n","  let x_max = -x_min;\n","  let y_min = Infinity;\n","  let y_max = -x_min;\n","\n","  tree_struct.each(d => {\n","    if (d.x > x_max) x_max = d.x;\n","    if (d.x < x_min) x_min = d.x;\n","    if (d.y > y_max) y_max = d.y;\n","    if (d.y < y_min) y_min = d.y;\n","  });\n","\n","  // Size of the plot.\n","  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n","  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n","      options.node_y_offset - options.node_y_size;\n","\n","  const plot = d3.select(canvas_id);\n","\n","  // Tool tip\n","  options.tooltip = plot.append('div')\n","                        .attr('width', 100)\n","                        .attr('height', 100)\n","                        .style('padding', '4px')\n","                        .style('background', '#fff')\n","                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n","                        .style('border', '1px solid black')\n","                        .style('font-family', 'sans-serif')\n","                        .style('font-size', options.font_size)\n","                        .style('position', 'absolute')\n","                        .style('z-index', '10')\n","                        .attr('pointer-events', 'none')\n","                        .style('display', 'none');\n","\n","  // Create canvas\n","  const svg = plot.append('svg').attr('width', width).attr('height', height);\n","  const graph =\n","      svg.style('overflow', 'visible')\n","          .append('g')\n","          .attr('font-family', 'sans-serif')\n","          .attr('font-size', options.font_size)\n","          .attr(\n","              'transform',\n","              () => `translate(${options.margin},${\n","                  - x_min + options.node_y_offset / 2 + options.margin})`);\n","\n","  // Plot bounding box.\n","  if (options.show_plot_bounding_box) {\n","    svg.append('rect')\n","        .attr('width', width)\n","        .attr('height', height)\n","        .attr('fill', 'none')\n","        .attr('stroke-width', 1.0)\n","        .attr('stroke', 'black');\n","  }\n","\n","  // Draw the edges.\n","  display_edges(options, graph, tree_struct);\n","\n","  // Draw the nodes.\n","  display_nodes(options, graph, tree_struct);\n","}\n","\n","/**\n"," * Draw the nodes of the tree.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!graph} graph D3 search handle containing the graph.\n"," * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n"," *     data, etc.).\n"," */\n","function display_nodes(options, graph, tree_struct) {\n","  const nodes = graph.append('g')\n","                    .selectAll('g')\n","                    .data(tree_struct.descendants())\n","                    .join('g')\n","                    .attr('transform', d => `translate(${d.y},${d.x})`);\n","\n","  nodes.append('rect')\n","      .attr('x', 0.5)\n","      .attr('y', 0.5)\n","      .attr('width', options.node_x_size)\n","      .attr('height', options.node_y_size)\n","      .attr('stroke', 'lightgrey')\n","      .attr('stroke-width', 1)\n","      .attr('fill', 'white')\n","      .attr('y', -options.node_y_size / 2);\n","\n","  // Brackets on the right of condition nodes without children.\n","  non_leaf_node_without_children =\n","      nodes.filter(node => node.data.condition != null && node.children == null)\n","          .append('g')\n","          .attr('transform', `translate(${options.node_x_size},0)`);\n","\n","  non_leaf_node_without_children.append('path')\n","      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n","      .attr('fill', 'none')\n","      .attr('stroke-width', 1.0)\n","      .attr('stroke', '#F00');\n","\n","  non_leaf_node_without_children.append('path')\n","      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n","      .attr('fill', 'none')\n","      .attr('stroke-width', 1.0)\n","      .attr('stroke', '#0F0');\n","\n","  const node_content = nodes.append('g').attr(\n","      'transform',\n","      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n","\n","  node_content.append(node => create_node_element(options, node));\n","}\n","\n","/**\n"," * Creates the D3 content for a single node.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!node} node Node to draw.\n"," * @return {!d3} D3 content.\n"," */\n","function create_node_element(options, node) {\n","  // Output accumulator.\n","  let output = {\n","    // Content to draw.\n","    content: d3.create('svg:g'),\n","    // Vertical offset to the next element to draw.\n","    vertical_offset: 0\n","  };\n","\n","  // Conditions.\n","  if (node.data.condition != null) {\n","    display_condition(options, node.data.condition, output);\n","  }\n","\n","  // Values.\n","  if (node.data.value != null) {\n","    display_value(options, node.data.value, output);\n","  }\n","\n","  // Explanations.\n","  if (node.data.explanation != null) {\n","    display_explanation(options, node.data.explanation, output);\n","  }\n","\n","  return output.content.node();\n","}\n","\n","\n","/**\n"," * Adds a single line of text inside of a node.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {string} text Text to display.\n"," * @param {!output} output Output display accumulator.\n"," */\n","function display_node_text(options, text, output) {\n","  output.content.append('text')\n","      .attr('x', options.node_padding)\n","      .attr('y', output.vertical_offset)\n","      .attr('alignment-baseline', 'hanging')\n","      .text(text);\n","  output.vertical_offset += 10;\n","}\n","\n","/**\n"," * Adds a single line of text inside of a node with a tooltip.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {string} text Text to display.\n"," * @param {string} tooltip Text in the Tooltip.\n"," * @param {!output} output Output display accumulator.\n"," */\n","function display_node_text_with_tooltip(options, text, tooltip, output) {\n","  const item = output.content.append('text')\n","                   .attr('x', options.node_padding)\n","                   .attr('alignment-baseline', 'hanging')\n","                   .text(text);\n","\n","  add_tooltip(options, item, () => tooltip);\n","  output.vertical_offset += 10;\n","}\n","\n","/**\n"," * Adds a tooltip to a dom element.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!dom} target Dom element to equip with a tooltip.\n"," * @param {!func} get_content Generates the html content of the tooltip.\n"," */\n","function add_tooltip(options, target, get_content) {\n","  function show(d) {\n","    options.tooltip.style('display', 'block');\n","    options.tooltip.html(get_content());\n","  }\n","\n","  function hide(d) {\n","    options.tooltip.style('display', 'none');\n","  }\n","\n","  function move(d) {\n","    options.tooltip.style('display', 'block');\n","    options.tooltip.style('left', (d.pageX + 5) + 'px');\n","    options.tooltip.style('top', d.pageY + 'px');\n","  }\n","\n","  target.on('mouseover', show);\n","  target.on('mouseout', hide);\n","  target.on('mousemove', move);\n","}\n","\n","/**\n"," * Adds a condition inside of a node.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!condition} condition Condition to display.\n"," * @param {!output} output Output display accumulator.\n"," */\n","function display_condition(options, condition, output) {\n","  threshold_format = d3.format('r');\n","\n","  if (condition.type === 'IS_MISSING') {\n","    display_node_text(options, `${condition.attribute} is missing`, output);\n","    return;\n","  }\n","\n","  if (condition.type === 'IS_TRUE') {\n","    display_node_text(options, `${condition.attribute} is true`, output);\n","    return;\n","  }\n","\n","  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n","    format = d3.format('r');\n","    display_node_text(\n","        options,\n","        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n","        output);\n","    return;\n","  }\n","\n","  if (condition.type === 'CATEGORICAL_IS_IN') {\n","    display_node_text_with_tooltip(\n","        options, `${condition.attribute} in [...]`,\n","        `${condition.attribute} in [${condition.mask}]`, output);\n","    return;\n","  }\n","\n","  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n","    display_node_text_with_tooltip(\n","        options, `${condition.attribute} intersect [...]`,\n","        `${condition.attribute} intersect [${condition.mask}]`, output);\n","    return;\n","  }\n","\n","  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n","    display_node_text_with_tooltip(\n","        options, `Sparse oblique split...`,\n","        `[${condition.attributes}]*[${condition.weights}]>=${\n","            threshold_format(condition.threshold)}`,\n","        output);\n","    return;\n","  }\n","\n","  display_node_text(\n","      options, `Non supported condition ${condition.type}`, output);\n","}\n","\n","/**\n"," * Adds a value inside of a node.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!value} value Value to display.\n"," * @param {!output} output Output display accumulator.\n"," */\n","function display_value(options, value, output) {\n","  if (value.type === 'PROBABILITY') {\n","    const left_margin = 0;\n","    const right_margin = 50;\n","    const plot_width = options.node_x_size - options.node_padding * 2 -\n","        left_margin - right_margin;\n","\n","    let cusum = Array.from(d3.cumsum(value.distribution));\n","    cusum.unshift(0);\n","    const distribution_plot = output.content.append('g').attr(\n","        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n","\n","    distribution_plot.selectAll('rect')\n","        .data(value.distribution)\n","        .join('rect')\n","        .attr('height', 10)\n","        .attr(\n","            'x',\n","            (d, i) =>\n","                (cusum[i] * plot_width + left_margin + options.node_padding))\n","        .attr('width', (d, i) => d * plot_width)\n","        .style('fill', (d, i) => d3.schemeSet1[i]);\n","\n","    const num_examples =\n","        output.content.append('g')\n","            .attr('transform', `translate(0,${output.vertical_offset})`)\n","            .append('text')\n","            .attr('x', options.node_x_size - options.node_padding)\n","            .attr('alignment-baseline', 'hanging')\n","            .attr('text-anchor', 'end')\n","            .text(`(${value.num_examples})`);\n","\n","    const distribution_details = d3.create('ul');\n","    distribution_details.selectAll('li')\n","        .data(value.distribution)\n","        .join('li')\n","        .append('span')\n","        .text(\n","            (d, i) =>\n","                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n","\n","    add_tooltip(options, distribution_plot, () => distribution_details.html());\n","    add_tooltip(options, num_examples, () => 'Number of examples');\n","\n","    output.vertical_offset += 10;\n","    return;\n","  }\n","\n","  if (value.type === 'REGRESSION') {\n","    display_node_text(\n","        options,\n","        'value: ' + d3.format('r')(value.value) + ` (` +\n","            d3.format('.6')(value.num_examples) + `)`,\n","        output);\n","    return;\n","  }\n","\n","  display_node_text(options, `Non supported value ${value.type}`, output);\n","}\n","\n","/**\n"," * Adds an explanation inside of a node.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!explanation} explanation Explanation to display.\n"," * @param {!output} output Output display accumulator.\n"," */\n","function display_explanation(options, explanation, output) {\n","  // Margin before the explanation.\n","  output.vertical_offset += 10;\n","\n","  display_node_text(\n","      options, `Non supported explanation ${explanation.type}`, output);\n","}\n","\n","\n","/**\n"," * Draw the edges of the tree.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!graph} graph D3 search handle containing the graph.\n"," * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n"," *     data, etc.).\n"," */\n","function display_edges(options, graph, tree_struct) {\n","  // Draw an edge between a parent and a child node with a bezier.\n","  function draw_single_edge(d) {\n","    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n","        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n","        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n","        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n","  }\n","\n","  graph.append('g')\n","      .attr('fill', 'none')\n","      .attr('stroke-width', 1.2)\n","      .selectAll('path')\n","      .data(tree_struct.links())\n","      .join('path')\n","      .attr('d', draw_single_edge)\n","      .attr(\n","          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n","}\n","\n","display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"REGRESSION\", \"value\": -2.1855042220408905e-08, \"num_examples\": 16996.0, \"standard_deviation\": 0.4464282663721316}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"time_diff_max_4\", \"threshold\": 51588.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": -0.05660685896873474, \"num_examples\": 6346.0, \"standard_deviation\": 0.48721302982108033}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"fqid_count_3\", \"threshold\": 20.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": -0.09934540838003159, \"num_examples\": 3422.0, \"standard_deviation\": 0.4992608728295972}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"screen_coor_x_sum_3\", \"threshold\": 43061.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": -0.16390123963356018, \"num_examples\": 675.0, \"standard_deviation\": 0.4895932241361765}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"screen_coor_x_mean_4\", \"threshold\": 203.39834594726562}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": -0.08348258584737778, \"num_examples\": 2747.0, \"standard_deviation\": 0.49653155274517613}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"time_diff_max_4\", \"threshold\": 73154.5}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": -0.0065893069840967655, \"num_examples\": 2924.0, \"standard_deviation\": 0.4528131700412131}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"time_diff_median_1\", \"threshold\": 782.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 0.005898436065763235, \"num_examples\": 2505.0, \"standard_deviation\": 0.4403021793877418}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"fqid_count_3\", \"threshold\": 13.5}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": -0.08124753087759018, \"num_examples\": 419.0, \"standard_deviation\": 0.4959838488757826}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"room_coor_y_min_3\", \"threshold\": -302.62152099609375}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 0.03373021259903908, \"num_examples\": 10650.0, \"standard_deviation\": 0.4055928278656675}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"time_diff_median_2\", \"threshold\": 614.75}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 0.05924773961305618, \"num_examples\": 7630.0, \"standard_deviation\": 0.36356460062638873}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"fqid_count_3\", \"threshold\": 20.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 0.023326322436332703, \"num_examples\": 2597.0, \"standard_deviation\": 0.419763106594738}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"fqid_count\", \"threshold\": 123.5}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 0.07778298109769821, \"num_examples\": 5033.0, \"standard_deviation\": 0.3247383651691776}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"time_diff_median_1\", \"threshold\": 897.75}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": -0.030739564448595047, \"num_examples\": 3020.0, \"standard_deviation\": 0.4723710535921351}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"time_diff_sum_4\", \"threshold\": 37886.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": -0.07083655893802643, \"num_examples\": 1512.0, \"standard_deviation\": 0.49289441153142616}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"time_diff_median_1\", \"threshold\": 808.25}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 0.009463788941502571, \"num_examples\": 1508.0, \"standard_deviation\": 0.4364040264608538}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"time_diff_max_4\", \"threshold\": 16796.0}}]}]}]}, \"#tree_plot_a07530f425524bdb8aa0d84898c28d23\")\n","</script>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["tfdf.model_plotter.plot_model_in_colab(models['1'], tree_idx=0, max_depth=3)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PIK5aUH-n2PH"},"source":["# Threshold-Moving for Imbalanced Classification\n","\n","Since the values of the column `correct` is fairly imbalanced, using the default threshold of `0.5` to map the predictions into classes 0 or 1 can result in poor performance. \n","In such cases, to improve performance we will calculate the `F1 score` for a certain range of thresholds and try to find the best threshold aka, threshold with highest `F1 score`. Then we will use this threshold to map the predicted probabilities to class labels 0 or 1.\n","\n","Please note that we are using `F1 score` since it is a better metric than `accuracy` to evaluate problems with class imbalance."]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T15:03:33.348866Z","iopub.status.busy":"2023-04-11T15:03:33.348399Z","iopub.status.idle":"2023-04-11T15:03:34.525896Z","shell.execute_reply":"2023-04-11T15:03:34.524896Z","shell.execute_reply.started":"2023-04-11T15:03:33.348829Z"},"id":"2wptRs3In2PH","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /home/thor_01/miniconda3/envs/ds2023/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:From /home/thor_01/miniconda3/envs/ds2023/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"]},{"name":"stdout","output_type":"stream","text":["Best threshold  0.6200000000000002 \tF1 score  0.685995\n"]}],"source":["# Create a dataframe of required size:\n","# (no: of users in validation set x no: of questions) initialized to zero values\n","# to store true values of the label `correct`. \n","true_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n","for i in range(18):\n","    # Get the true labels.\n","    tmp = labels.loc[labels.q == i+1].set_index('session').loc[VALID_USER_LIST]\n","    true_df[i] = tmp.correct.values\n","\n","max_score = 0; best_threshold = 0\n","\n","# Loop through threshold values from 0.4 to 0.8 and select the threshold with \n","# the highest `F1 score`.\n","for threshold in np.arange(0.4,0.8,0.01):\n","    metric = tfa.metrics.F1Score(num_classes=2,average=\"macro\",threshold=threshold)\n","    y_true = tf.one_hot(true_df.values.reshape((-1)), depth=2)\n","    y_pred = tf.one_hot((prediction_df.values.reshape((-1))>threshold).astype('int'), depth=2)\n","    metric.update_state(y_true, y_pred)\n","    f1_score = metric.result().numpy()\n","    if f1_score > max_score:\n","        max_score = f1_score\n","        best_threshold = threshold\n","        \n","print(\"Best threshold \", best_threshold, \"\\tF1 score \", max_score)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ezA40GQ4n2PH"},"source":["# Submission\n","\n","Here you'll use the `best_threshold` calculate in the previous cell"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T15:07:46.993288Z","iopub.status.busy":"2023-04-11T15:07:46.992778Z","iopub.status.idle":"2023-04-11T15:07:48.902986Z","shell.execute_reply":"2023-04-11T15:07:48.901928Z","shell.execute_reply.started":"2023-04-11T15:07:46.993246Z"},"id":"gHiXTnTVn2PI","trusted":true},"outputs":[],"source":["# Reference\n","# https://www.kaggle.com/code/philculliton/basic-submission-demo\n","# https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\n","\n","\n","import jo_wilder\n","env = jo_wilder.make_env()\n","iter_test = env.iter_test()\n","\n","limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n","\n","count = 0\n","\n","for (sample_submission, test) in iter_test:\n","        \n","        session_id = test.session_id.values[0]\n","        gr = test.level_group.values[0]\n","        a,b = limits[grp]\n","  \n","\n","        # ------------------- level 0-4 ---------------------------------\n","        if a == 1:\n","            test = feature_engineer(test, gr)\n","            \n","\n","        # ------------------- level 5-12 ---------------------------------\n","        elif a == 4:\n","            test = feature_engineer(test, gr)\n","\n","        # ------------------- level 13-22 ---------------------------------    \n","        elif a == 14:\n","            test = feature_engineer(test, gr)\n","        \n","        for t in range(a,b):\n","            gbtm = models[f'{grp}_{t}']\n","            test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test)\n","            predictions = gbtm.predict(test_ds)\n","            mask = sample_submission.session_id.str.contains(f'q{t}')\n","            n_predictions = (predictions > best_threshold).astype(int)\n","            sample_submission.loc[mask,'correct'] = n_predictions.flatten()\n","            \n","        env.predict(sample_submission)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T15:08:02.438826Z","iopub.status.busy":"2023-04-11T15:08:02.438390Z","iopub.status.idle":"2023-04-11T15:08:03.619129Z","shell.execute_reply":"2023-04-11T15:08:03.617743Z","shell.execute_reply.started":"2023-04-11T15:08:02.438789Z"},"id":"iYBXokAyn2PI","trusted":true},"outputs":[],"source":["! head submission.csv"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
